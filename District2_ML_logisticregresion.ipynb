{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c5b664",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11260/2050698247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdb_password\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "#importing possible libraries and dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e186cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating string to our Database, engine and calling in dataset\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/Arizona_Elections\"\n",
    "engine = create_engine(db_string)\n",
    "cleaning_district2_df= pd.read_sql('SELECT * from machinelearning - copy', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fa6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_district2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54455476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all columns contained unecesarry features or null nan \n",
    "cleaning_district2_df.drop(columns=['Voter Score','voter_id','Turnout Score','Kids in HH','Liberal Ideology'], inplace=True)\n",
    "cleaning_district2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target column values to low_chance and high_chance based on values\n",
    "\n",
    "x = {'False':'Low_Chance'}\n",
    "cleaning_district2_df = cleaning_district2_df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['True'],'High_Chance')\n",
    "cleaning_district2_df = cleaning_district2_df.replace(x)\n",
    "\n",
    "cleaning_district2_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "cleaning_district2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of our conditions\n",
    "conditions = [\n",
    "    (cleaning_district2_df['Age'] >= 18) & (df_voters['Age'] <= 24),\n",
    "    (cleaning_district2_df['Age'] >= 25) & (df_voters['Age'] <= 34),\n",
    "    (cleaning_district2_df['Age'] >= 35) & (df_voters['Age'] <=44),\n",
    "    (cleaning_district2_df['Age'] >= 45) & (df_voters['Age'] <=54),\n",
    "    (cleaning_district2_df['Age'] >= 55) & (df_voters['Age'] <=64),\n",
    "    (cleaning_district2_df['Age'] >= 65),\n",
    "    ]\n",
    "\n",
    "# Create of values we want assigned to the conditions\n",
    "values = ['1', '2', '3','4','5','6']\n",
    "\n",
    "# Create a new column with np.select to assign values to it using our lists as arguments\n",
    "cleaning_district2_df['Age'] = np.select(conditions, values)\n",
    "\n",
    "# Display updated DataFrame\n",
    "cleaning_district2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing if age code is working properly by adding unique values\n",
    "print(cleaning_district2_df['Age'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting label columns from text to numerical data as model only works with numerical data\n",
    "\n",
    "X = pd.get_dummies(df_voters, columns=[\"Party\",\"Sex\",\"Ethnicity\",'Zip']).drop(\"Swing Voter\", axis=1)\n",
    "\n",
    "# Create our target\n",
    "\n",
    "y = cleaning_district2_df[\"Swing Voter\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebac76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying out target was selected correclty\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01422657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our training sample and testing sample \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "# Check balances\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling using logistic regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking our resample counters\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression being process\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out our matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0174af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing accuracy scores\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cee925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the classification report to see our scores\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3323023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual High_chane\", \"Actual low_Chance\"], columns=[\"Predicted high_Chance\", \"Predicted low_Chance\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to view our results\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef970c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
